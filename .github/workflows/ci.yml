# .github/workflows/ci.yml
# This is the full GitHub Actions workflow file.

name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  CARGO_TERM_COLOR: always
  CARGO_TARGET_DIR: ${{ github.workspace }}/target # Consistent target dir
  RUST_BACKTRACE: 1

jobs:
  # This job will now run your comprehensive script
  comprehensive-tests:
    name: Comprehensive Tests & Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4 # Updated to v4

      - name: Install Rust (stable)
        uses: actions/setup-rust@v1 # Using the official setup-rust action
        with:
          toolchain: stable
          # Optional: enable caching
          # cache: true

      - name: Install system prerequisites for tests and benchmarks
        run: |
          sudo apt-get update
          sudo apt-get install -y hyperfine jq bc # For benchmarks within run_all_tests.sh

      - name: Ensure run_all_tests.sh is executable
        run: chmod +x ./run_all_tests.sh

      - name: Run Comprehensive Test Script
        # This script should now handle:
        # - Building and installing Marlin
        # - Running cargo test --all
        # - Generating test corpus
        # - Running bench/dirty-vs-full.sh (produces dirty-vs-full.md)
        # - (Optional) Running the cold-start benchmark (produces perf.json or similar)
        # - Running the demo flow tests
        run: ./run_all_tests.sh

      - name: Upload Dirty vs Full Benchmark Report
        uses: actions/upload-artifact@v4
        with:
          name: marlin-dirty-vs-full-benchmark-report
          path: bench/dirty-vs-full.md
          if-no-files-found: warn # Don't fail if the file isn't there, just warn
          retention-days: 7

      # If your run_all_tests.sh now also creates perf.json for cold-start
      - name: Upload Cold Start Benchmark JSON (if generated by script)
        uses: actions/upload-artifact@v4
        if: ${{ success() }} # Only if previous steps succeed
        with:
          name: marlin-cold-start-perf-json
          path: perf.json # Assuming run_all_tests.sh now creates this
          if-no-files-found: ignore # Okay if this specific file isn't generated
          retention-days: 7

  coverage:
    name: Code Coverage (Tarpaulin)
    needs: comprehensive-tests # Run after the main tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust (nightly for Tarpaulin, if needed)
        uses: actions/setup-rust@v1
        with:
          toolchain: nightly # Or stable if Tarpaulin works well with it for your project
          override: true
          components: llvm-tools-preview # Component needed by Tarpaulin

      - name: Install system prerequisites for Tarpaulin
        run: |
          sudo apt-get update
          sudo apt-get install -y pkg-config libssl-dev # Keep if your build needs them

      - name: Install cargo-tarpaulin
        run: cargo install cargo-tarpaulin

      - name: Code Coverage (libmarlin only)
        # MARLIN_DB_PATH should be unset or point to a temp location for isolated test runs
        run: |
          unset MARLIN_DB_PATH
          cargo +nightly tarpaulin --package libmarlin --out Html --out Xml --fail-under 85
        continue-on-error: true # So the workflow doesn't fail if coverage is low during development

      - name: Upload HTML Coverage Report
        uses: actions/upload-artifact@v4
        with:
          name: marlin-coverage-report-html
          path: tarpaulin-report.html
          if-no-files-found: warn
          retention-days: 7

      - name: Upload XML Coverage Report (for services like Codecov)
        uses: actions/upload-artifact@v4
        with:
          name: marlin-coverage-report-xml
          path: cobertura.xml # Default XML output name for Tarpaulin
          if-no-files-found: warn
          retention-days: 7